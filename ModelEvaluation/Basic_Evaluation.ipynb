{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import CSVLoader,PyPDFLoader\n",
    "from langchain.llms import openai\n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "from langchain.evaluation.qa import QAEvalChain\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"openai_api_key\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=os.getenv(\"LANGCHAIN_TRACING_V2\")\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"]=os.getenv(\"LANGCHAIN_ENDPOINT\")\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ls__de07eaff0383465f9b5b9f689fa3e61a'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getenv(\"LANGCHAIN_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader=PyPDFLoader(\"MachineLearning-Lecture01.pdf\")\n",
    "load=loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.evaluation.qa import QAGenerateChain\n",
    "llm=openai.OpenAI()\n",
    "question=QAGenerateChain.from_llm(\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QAGenerateChain(prompt=PromptTemplate(input_variables=['doc'], template='You are a teacher coming up with questions to ask on a quiz. \\nGiven the following document, please generate a question and answer based on that document.\\n\\nExample Format:\\n<Begin Document>\\n...\\n<End Document>\\nQUESTION: question here\\nANSWER: answer here\\n\\nThese questions should be detailed and be based explicitly on information in the document. Begin!\\n\\n<Begin Document>\\n{doc}\\n<End Document>'), llm=OpenAI(client=<class 'openai.api_resources.completion.Completion'>, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy=''))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "item=[{\"doc\":t} for t in load[:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/basitarif/Downloads/important_software/anaconda3/lib/python3.11/site-packages/langchain/chains/llm.py:308: UserWarning: The apply_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "examples=question.apply_and_parse(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Who is the instructor of the machine learning class?'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples[0][\"qa_pairs\"][\"query\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector=Chroma.from_documents(\n",
    "    embedding=OpenAIEmbeddings(),\n",
    "    documents=load[:5]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "BaseRetrievalQA.from_chain_type() missing 1 required positional argument: 'llm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m qachain\u001b[38;5;241m=\u001b[39mRetrievalQA\u001b[38;5;241m.\u001b[39mfrom_chain_type(\n\u001b[1;32m      2\u001b[0m     chain_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstuff\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     retriever\u001b[38;5;241m=\u001b[39mvector\u001b[38;5;241m.\u001b[39mas_retriever()\n\u001b[1;32m      4\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: BaseRetrievalQA.from_chain_type() missing 1 required positional argument: 'llm'"
     ]
    }
   ],
   "source": [
    "qachain=RetrievalQA.from_chain_type(\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vector.as_retriever()\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='MachineLearning-Lecture01  \\nInstructor (Andrew Ng):  Okay. Good morning. Welcome to CS229, the machine \\nlearning class. So what I wanna do today is ju st spend a little time going over the logistics \\nof the class, and then we\\'ll start to  talk a bit about machine learning.  \\nBy way of introduction, my name\\'s  Andrew Ng and I\\'ll be instru ctor for this class. And so \\nI personally work in machine learning, and I\\' ve worked on it for about 15 years now, and \\nI actually think that machine learning is th e most exciting field of all the computer \\nsciences. So I\\'m actually always excited about  teaching this class. Sometimes I actually \\nthink that machine learning is not only the most exciting thin g in computer science, but \\nthe most exciting thing in all of human e ndeavor, so maybe a little bias there.  \\nI also want to introduce the TAs, who are all graduate students doing research in or \\nrelated to the machine learni ng and all aspects of machin e learning. Paul Baumstarck \\nworks in machine learning and computer vision.  Catie Chang is actually a neuroscientist \\nwho applies machine learning algorithms to try to understand the human brain. Tom Do \\nis another PhD student, works in computa tional biology and in sort of the basic \\nfundamentals of human learning. Zico Kolter is  the head TA — he\\'s head TA two years \\nin a row now — works in machine learning a nd applies them to a bunch of robots. And \\nDaniel Ramage is — I guess he\\'s not here  — Daniel applies l earning algorithms to \\nproblems in natural language processing.  \\nSo you\\'ll get to know the TAs and me much be tter throughout this quarter, but just from \\nthe sorts of things the TA\\'s do, I hope you can  already tell that machine learning is a \\nhighly interdisciplinary topic in which just the TAs find l earning algorithms to problems \\nin computer vision and biology and robots a nd language. And machine learning is one of \\nthose things that has and is having a large impact on many applications.  \\nSo just in my own daily work, I actually frequently end up talking to people like \\nhelicopter pilots to biologists to people in  computer systems or databases to economists \\nand sort of also an unending stream of  people from industry coming to Stanford \\ninterested in applying machine learni ng methods to their own problems.  \\nSo yeah, this is fun. A couple of weeks ago, a student actually forwar ded to me an article \\nin \"Computer World\" about the 12 IT skills th at employers can\\'t say no to. So it\\'s about \\nsort of the 12 most desirabl e skills in all of IT and all of information technology, and \\ntopping the list was actually machine lear ning. So I think this is a good time to be \\nlearning this stuff and learning algorithms and having a large impact on many segments \\nof science and industry.  \\nI\\'m actually curious about something. Learni ng algorithms is one of the things that \\ntouches many areas of science and industrie s, and I\\'m just kind of curious. How many \\npeople here are computer science majors, are in the computer science department? Okay. \\nAbout half of you. How many people are from  EE? Oh, okay, maybe about a fifth. How ', metadata={'page': 0, 'source': 'MachineLearning-Lecture01.pdf'}),\n",
       " Document(page_content=\"many biologers are there here? Wow, just a few, not many. I'm surprised. Anyone from \\nstatistics? Okay, a few. So where are the rest of you from?  \\nStudent : iCME.  \\nInstructor (Andrew Ng) : Say again?  \\nStudent : iCME.  \\nInstructor (Andrew Ng) : iCME. Cool.  \\nStudent : [Inaudible].  \\nInstructor (Andrew Ng) : Civi and what else?  \\nStudent : [Inaudible]  \\nInstructor (Andrew Ng) : Synthesis, [inaudible] systems. Yeah, cool.  \\nStudent : Chemi.  \\nInstructor (Andrew Ng) : Chemi. Cool.  \\nStudent : [Inaudible].  \\nInstructor (Andrew Ng) : Aero/astro. Yes, right. Yeah, okay, cool. Anyone else?  \\nStudent : [Inaudible].  \\nInstructor (Andrew Ng) : Pardon? MSNE. All ri ght. Cool. Yeah.  \\nStudent : [Inaudible].  \\nInstructor (Andrew Ng) : Pardon?  \\nStudent : [Inaudible].  \\nInstructor (Andrew Ng) : Endo —  \\nStudent : [Inaudible].  \\nInstructor (Andrew Ng) : Oh, I see, industry. Okay. Cool. Great, great. So as you can \\ntell from a cross-section of th is class, I think we're a very diverse audience in this room, \\nand that's one of the things that makes this class fun to teach and fun to be in, I think.  \", metadata={'page': 1, 'source': 'MachineLearning-Lecture01.pdf'}),\n",
       " Document(page_content=\"of this class will not be very program ming intensive, although we will do some \\nprogramming, mostly in either MATLAB or Octa ve. I'll say a bit more about that later.  \\nI also assume familiarity with basic proba bility and statistics. So most undergraduate \\nstatistics class, like Stat 116 taught here at Stanford, will be more than enough. I'm gonna \\nassume all of you know what ra ndom variables are, that all of you know what expectation \\nis, what a variance or a random variable is. And in case of some of you, it's been a while \\nsince you've seen some of this material. At some of the discussion sections, we'll actually \\ngo over some of the prerequisites, sort of as  a refresher course under prerequisite class. \\nI'll say a bit more about that later as well.  \\nLastly, I also assume familiarity with basi c linear algebra. And again, most undergraduate \\nlinear algebra courses are more than enough. So if you've taken courses like Math 51, \\n103, Math 113 or CS205 at Stanford, that would be more than enough. Basically, I'm \\ngonna assume that all of you know what matrix es and vectors are, that you know how to \\nmultiply matrices and vectors and multiply matrix and matrices, that you know what a matrix inverse is. If you know what an eigenvect or of a matrix is, that'd be even better. \\nBut if you don't quite know or if you're not qu ite sure, that's fine, too. We'll go over it in \\nthe review sections.  \\nSo there are a couple more logisti cal things I should deal with in  this class. One is that, as \\nmost of you know, CS229 is a televised cla ss. And in fact, I guess many of you are \\nprobably watching this at home on TV, so I' m gonna say hi to our home viewers.  \\nSo earlier this year, I appro ached SCPD, which televises th ese classes, about trying to \\nmake a small number of Stanford classes publ icly available or posting the videos on the \\nweb. And so this year, Stanford is actually starting a small pilot program in which we'll \\npost videos of a small number of classes onlin e, so on the Internet in a way that makes it \\npublicly accessible to everyone. I'm very exc ited about that because machine learning in \\nschool, let's get the word out there.  \\nOne of the consequences of this is that — let's see — so videos  or pictures of the students \\nin this classroom will not be posted online, so your images — so don't worry about being \\nby seeing your own face appear on YouTube one day. But the microphones may pick up your voices, so I guess the consequence of that is that because microphones may pick up your voices, no matter how irritated you are at  me, don't yell out swear words in the \\nmiddle of class, but because there won't be video you can safely sit there and make faces \\nat me, and that won't show, okay?  \\nLet's see. I also handed out this — ther e were two handouts I hope most of you have, \\ncourse information handout. So let me just sa y a few words about parts of these. On the \\nthird page, there's a section that says Online Resources.  \\nOh, okay. Louder? Actually, could you turn up the volume? Testing. Is this better? \\nTesting, testing. Okay, cool. Thanks.  \", metadata={'page': 4, 'source': 'MachineLearning-Lecture01.pdf'}),\n",
       " Document(page_content=\"Similarly, every time you write a check, I ac tually don't know the number for this, but a \\nsignificant fraction of checks that you write are processed by a learning algorithm that's \\nlearned to read the digits, so the dolla r amount that you wrote down on your check. So \\nevery time you write a check, there's anot her learning algorithm that you're probably \\nusing without even being aware of it.  \\nIf you use a credit card, or I know at least one phone compan y was doing this, and lots of \\ncompanies like eBay as well that do electr onic transactions, there's a good chance that \\nthere's a learning algorithm in the backgr ound trying to figure out if, say, your credit \\ncard's been stolen or if someone's engaging in a fraudulent transaction.  \\nIf you use a website like Amazon or Netflix that will often recommend books for you to \\nbuy or movies for you to rent or whatever , these are other examples of learning \\nalgorithms that have learned what sorts of th ings you like to buy or what sorts of movies \\nyou like to watch and can therefore give  customized recommendations to you.  \\nJust about a week ago, I had my car serviced, and even there, my car mechanic was trying \\nto explain to me some learning algorithm in th e innards of my car th at's sort of doing its \\nbest to optimize my driving performan ce for fuel efficiency or something.  \\nSo, see, most of us use learning algorithms half a dozen, a dozen, maybe dozens of times \\nwithout even knowing it.  \\nAnd of course, learning algorithms are also  doing things like giving us a growing \\nunderstanding of the human genome. So if so meday we ever find a cure for cancer, I bet \\nlearning algorithms will have had a large role in that. That's sort of the thing that Tom \\nworks on, yes?  \\nSo in teaching this class, I sort of have thre e goals. One of them is just to I hope convey \\nsome of my own excitement a bout machine learning to you.  \\nThe second goal is by the end of this class, I hope all of you will be ab le to apply state-of-\\nthe-art machine learning algorithms to whatev er problems you're interested in. And if you \\never need to build a system for reading zi p codes, you'll know how to do that by the end \\nof this class.  \\nAnd lastly, by the end of this class, I reali ze that only a subset of  you are interested in \\ndoing research in machine learning, but by the c onclusion of this class,  I hope that all of \\nyou will actually be well qualified to star t doing research in machine learning, okay?  \\nSo let's say a few words about logistics. The prerequisites of this class are written on one \\nof the handouts, are as follows: In this class, I'm going to assume that all of you have sort \\nof basic knowledge of computer science and kn owledge of the basic computer skills and \\nprinciples. So I assume all of you know what big?O notation, that all of you know about \\nsort of data structures like  queues, stacks, binary trees , and that all of you know enough \\nprogramming skills to, like, write a simple co mputer program. And it turns out that most \", metadata={'page': 3, 'source': 'MachineLearning-Lecture01.pdf'})]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "template=PromptTemplate.from_template(\"You are a teacher coming up with questions to ask on a quiz. \\nGiven the following document, `please generate a question and answer based on that document atleast 5.\\n\\nExample Format:\\n<Begin Document>\\\n",
    "\\n...\\n<End Document>\\nQUESTION: question here\\nANSWER: answer here\\n\\nThese questions should be detailed and be based explicitly on information in the document. Begin!\\n\\n<Begin Document>\\n{doc}\\n<End Document>'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_list=[{\"doc\":t} for t in load[:2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doc': Document(page_content='MachineLearning-Lecture01  \\nInstructor (Andrew Ng):  Okay. Good morning. Welcome to CS229, the machine \\nlearning class. So what I wanna do today is ju st spend a little time going over the logistics \\nof the class, and then we\\'ll start to  talk a bit about machine learning.  \\nBy way of introduction, my name\\'s  Andrew Ng and I\\'ll be instru ctor for this class. And so \\nI personally work in machine learning, and I\\' ve worked on it for about 15 years now, and \\nI actually think that machine learning is th e most exciting field of all the computer \\nsciences. So I\\'m actually always excited about  teaching this class. Sometimes I actually \\nthink that machine learning is not only the most exciting thin g in computer science, but \\nthe most exciting thing in all of human e ndeavor, so maybe a little bias there.  \\nI also want to introduce the TAs, who are all graduate students doing research in or \\nrelated to the machine learni ng and all aspects of machin e learning. Paul Baumstarck \\nworks in machine learning and computer vision.  Catie Chang is actually a neuroscientist \\nwho applies machine learning algorithms to try to understand the human brain. Tom Do \\nis another PhD student, works in computa tional biology and in sort of the basic \\nfundamentals of human learning. Zico Kolter is  the head TA — he\\'s head TA two years \\nin a row now — works in machine learning a nd applies them to a bunch of robots. And \\nDaniel Ramage is — I guess he\\'s not here  — Daniel applies l earning algorithms to \\nproblems in natural language processing.  \\nSo you\\'ll get to know the TAs and me much be tter throughout this quarter, but just from \\nthe sorts of things the TA\\'s do, I hope you can  already tell that machine learning is a \\nhighly interdisciplinary topic in which just the TAs find l earning algorithms to problems \\nin computer vision and biology and robots a nd language. And machine learning is one of \\nthose things that has and is having a large impact on many applications.  \\nSo just in my own daily work, I actually frequently end up talking to people like \\nhelicopter pilots to biologists to people in  computer systems or databases to economists \\nand sort of also an unending stream of  people from industry coming to Stanford \\ninterested in applying machine learni ng methods to their own problems.  \\nSo yeah, this is fun. A couple of weeks ago, a student actually forwar ded to me an article \\nin \"Computer World\" about the 12 IT skills th at employers can\\'t say no to. So it\\'s about \\nsort of the 12 most desirabl e skills in all of IT and all of information technology, and \\ntopping the list was actually machine lear ning. So I think this is a good time to be \\nlearning this stuff and learning algorithms and having a large impact on many segments \\nof science and industry.  \\nI\\'m actually curious about something. Learni ng algorithms is one of the things that \\ntouches many areas of science and industrie s, and I\\'m just kind of curious. How many \\npeople here are computer science majors, are in the computer science department? Okay. \\nAbout half of you. How many people are from  EE? Oh, okay, maybe about a fifth. How ', metadata={'source': './MachineLearning-Lecture01.pdf', 'page': 0})}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "setingtemplate=template.format(\n",
    "    doc=load[:2]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'LLMChain' has no attribute 'output_parser'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LLMChain\n\u001b[0;32m----> 2\u001b[0m llm_chain \u001b[38;5;241m=\u001b[39m LLMChain\u001b[38;5;241m.\u001b[39moutput_parser(llm\u001b[38;5;241m=\u001b[39mllm)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(llm_chain\u001b[38;5;241m.\u001b[39mapply(load))\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'LLMChain' has no attribute 'output_parser'"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "llm_chain = LLMChain.output_parser(llm=llm)\n",
    "print(llm_chain.apply(load))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello there! How can I assist you today?')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "llm.invoke(\"Hello, world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain.evaluation.qa.eval_chain.QAEvalChain"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "78a73e9cea53431a004a8cb57099f417374d636685740d6545615ecc2fea032b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
