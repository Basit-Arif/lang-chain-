{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import CSVLoader,PyPDFLoader\n",
    "from langchain.llms import openai\n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "from langchain.evaluation.qa import QAEvalChain\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"openai_api_key\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=os.getenv(\"LANGCHAIN_TRACING_V2\")\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"]=os.getenv(\"LANGCHAIN_ENDPOINT\")\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing PyPDFLoader to load the \"Statistic.pdf\" file\n",
    "loader = PyPDFLoader(\"Statistic.pdf\")\n",
    "load = loader.load()\n",
    "# Adding a commit related to the loaded content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.evaluation.qa import QAGenerateChain\n",
    "llm=openai.OpenAI()\n",
    "# Importing a module to generate question-answer chains\n",
    "# using a language model (llm) from OpenAI\n",
    "question = QAGenerateChain.from_llm(\n",
    "    llm=openai.OpenAI()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QAGenerateChain(prompt=PromptTemplate(input_variables=['doc'], template='You are a teacher coming up with questions to ask on a quiz. \\nGiven the following document, please generate a question and answer based on that document.\\n\\nExample Format:\\n<Begin Document>\\n...\\n<End Document>\\nQUESTION: question here\\nANSWER: answer here\\n\\nThese questions should be detailed and be based explicitly on information in the document. Begin!\\n\\n<Begin Document>\\n{doc}\\n<End Document>'), llm=OpenAI(client=<class 'openai.api_resources.completion.Completion'>, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy=''))"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question # this a prompt behind QAGenerateChain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of dictionaries\n",
    "# Each dictionary contains a key \"doc\" with a value from the subset of elements in the \"load\" list,\n",
    "# specifically elements indexed from 50 to 59 (inclusive).\n",
    "item=[{\"doc\":t} for t in load[50:60]]\n",
    "# we did that because there is \"doc\" input_variable in QAGenerateChain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doc': Document(page_content=' 1.7 Big Data and Data Mining 19data collected can be substantial. For large retail companies, the sheer volume of data col-lected is hard to conceptualize, and figuring out how to effectively use these data to improve profitability is a challenge. Mass retailers such as Walmart capture data on 20 to 30 million transactions every day, telecommunication companies such as France Telecom and AT&T generate over 300 million call records per day, and Visa processes 6800 payment transac-tions per second or approximately 600 million transactions per day. In addition to the sheer volume and speed with which companies now collect data, more complicated types of data are now available and are proving to be of great value to businesses. Text data are collected by monitoring what is being said about a com-pany’s products or services on social media such as Twitter. Audio data are collected from service calls (on a service call, you will often hear “this call may be monitored for quality control”). Video data are collected by in-store video cameras to analyze shop-ping behavior. Analyzing information generated by these nontraditional sources is more complicated because of the complex process of transforming the information into data that can be analyzed.Larger and more complex data sets are now often referred to as big data. Although there does not seem to be a universally accepted definition of big data, many think if it as a set of data that cannot be managed, processed, or analyzed with commonly available software in a reasonable amount of time. Many data analysts define big data by refer-ring to the three v’s of data: volume, velocity, and variety. Volume refers to the amount of available data (the typical unit of measure for is now a terabyte, which is 1012 bytes); velocity refers to the speed at which data is collected and processed; and variety refers to the different data types.The term data warehousing is used to refer to the process of capturing, storing, and maintaining the data. Computing power and data collection tools have reached the point where it is now feasible to store and retrieve extremely large quantities of data in seconds. Analysis of the data in the warehouse may result in decisions that will lead to new strate-gies and higher profits for the organization. For example, General Electric (GE) captures a large amount of data from sensors on its aircraft engines each time a plane takes off or lands. Capturing these data allows GE to offer an important service to its customers; GE monitors the engine performance and can alert its customer when service is needed or a problem is likely to occur.The subject of data mining deals with methods for developing useful decision-making information from large databases. Using a combination of procedures from statistics, math-ematics, and computer science, analysts “mine the data” in the warehouse to convert it into useful information, hence the name data mining. Dr. Kurt Thearling, a leading practitioner in the field, defines data mining as “the automated extraction of predictive information from (large) databases.” The two key words in Dr. Thearling’s definition are “automated” and “predictive.” Data mining systems that are the most effective use automated procedures to extract information from the data using only the most general or even vague queries by the user. And data mining software automates the process of uncovering hidden predictive information that in the past required hands-on analysis.The major applications of data mining have been made by companies with a strong consumer focus, such as retail businesses, financial organizations, and communication companies. Data mining has been successfully used to help retailers such as Amazon and Barnes & Noble determine one or more related products that customers who have already purchased a specific product are also likely to purchase. Then, when a customer logs on to the company’s website and purchases a product, the website uses pop-ups to alert the customer about additional products that the customer is likely to purchase. In another appli-cation, data mining may be used to identify customers who are likely to spend more than $20 on a particular shopping trip. These customers may then be identified as the ones to receive special e-mail or regular mail discount offers to encourage them to make their next shopping trip  before the discount termination date.\\n85317_ch01_ptg01.indd   1906/01/16   2:13 PMCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s).Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', metadata={'source': 'Statistic.pdf', 'page': 50})}"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/basitarif/Downloads/important_software/anaconda3/lib/python3.11/site-packages/langchain/chains/llm.py:308: UserWarning: The apply_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "examples=question.apply_and_parse(item)\n",
    "# Applying the question-answer generation and parsing function to the list of dictionaries ('item')\n",
    "# The 'question' object generated earlier is being used here to apply and parse questions on the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a 'vector' by extracting chromatic features from the initial three documents in the 'load' list\n",
    "# Using the 'Chroma' method and incorporating 'OpenAIEmbeddings' for embedding purposes\n",
    "vector=Chroma.from_documents(\n",
    "    documents=load[:3],\n",
    "    embedding=OpenAIEmbeddings()\n",
    ")\n",
    "# we are doing this we want to see if the predicted answer from embedding is same as we get from original document "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'qa_pairs': {'query': 'What is the definition of big data according to many data analysts?',\n",
       "  'answer': 'Many data analysts define big data by referring to the three v’s of data: volume, velocity, and variety. Volume refers to the amount of available data, velocity refers to the speed at which data is collected and processed, and variety refers to the different data types.'}}"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we attempt to use this example with the RetrievalQa chain to get an answer, an error might occur. This is because the function required by RetrievalQa only accepts a \"query\" as input. To address this, we need to transform the above example variable into a suitable query format that RetrievalQa can process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_data = [{\"query\": item['qa_pairs']['query'], \"answer\": item['qa_pairs']['answer']} for item in examples]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'query': 'What is the definition of big data according to many data analysts?',\n",
       "  'answer': 'Many data analysts define big data by referring to the three v’s of data: volume, velocity, and variety. Volume refers to the amount of available data, velocity refers to the speed at which data is collected and processed, and variety refers to the different data types.'},\n",
       " {'query': 'What is one advantage that data mining has over classical statistics?',\n",
       "  'answer': 'Data mining has the advantage of having the ability to partition the data set so that a model developed for the training data set may be tested for reliability on other data.'},\n",
       " {'query': 'What is an example of unethical statistical behavior according to the American Statistical Association\\'s \"Ethical Guidelines for Statistical Practice\"?',\n",
       "  'answer': 'An example of unethical statistical behavior according to the American Statistical Association\\'s \"Ethical Guidelines for Statistical Practice\" is running multiple tests until a desired result is obtained, such as conducting repeated samples of a product until a sample mean of a certain value is obtained.'}]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a RetrievalQA chain using specific parameters:\n",
    "# 'chain_type' specifies the type of chain ('stuff' in this case)\n",
    "# 'retriever' utilizes the vector (extracted features) converted as a retriever\n",
    "# 'llm' denotes the language model (llm) used within the RetrievalQA chain\n",
    "qachain=RetrievalQA.from_chain_type(\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vector.as_retriever(),\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Incorrect API key provided: sk-8y8iE***************************************MZdG. You can find your API key at https://platform.openai.com/account/api-keys.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[200], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Applying the RetrievalQA chain ('qachain') to generate predictions on modified data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m prediction\u001b[38;5;241m=\u001b[39mqachain\u001b[38;5;241m.\u001b[39mapply(modified_data)\n",
      "File \u001b[0;32m~/Downloads/important_software/anaconda3/lib/python3.11/site-packages/langchain/chains/base.py:663\u001b[0m, in \u001b[0;36mChain.apply\u001b[0;34m(self, input_list, callbacks)\u001b[0m\n\u001b[1;32m    659\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m    660\u001b[0m     \u001b[39mself\u001b[39m, input_list: List[Dict[\u001b[39mstr\u001b[39m, Any]], callbacks: Callbacks \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    661\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]]:\n\u001b[1;32m    662\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the chain on all inputs in the list.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 663\u001b[0m     \u001b[39mreturn\u001b[39;00m [\u001b[39mself\u001b[39m(inputs, callbacks\u001b[39m=\u001b[39mcallbacks) \u001b[39mfor\u001b[39;00m inputs \u001b[39min\u001b[39;00m input_list]\n",
      "File \u001b[0;32m~/Downloads/important_software/anaconda3/lib/python3.11/site-packages/langchain/chains/base.py:663\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    659\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m    660\u001b[0m     \u001b[39mself\u001b[39m, input_list: List[Dict[\u001b[39mstr\u001b[39m, Any]], callbacks: Callbacks \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    661\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]]:\n\u001b[1;32m    662\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the chain on all inputs in the list.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 663\u001b[0m     \u001b[39mreturn\u001b[39;00m [\u001b[39mself\u001b[39m(inputs, callbacks\u001b[39m=\u001b[39mcallbacks) \u001b[39mfor\u001b[39;00m inputs \u001b[39min\u001b[39;00m input_list]\n",
      "File \u001b[0;32m~/Downloads/important_software/anaconda3/lib/python3.11/site-packages/langchain/chains/base.py:308\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    307\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 308\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    309\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    310\u001b[0m final_outputs: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(\n\u001b[1;32m    311\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[1;32m    312\u001b[0m )\n",
      "File \u001b[0;32m~/Downloads/important_software/anaconda3/lib/python3.11/site-packages/langchain/chains/base.py:302\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    295\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    296\u001b[0m     dumpd(\u001b[39mself\u001b[39m),\n\u001b[1;32m    297\u001b[0m     inputs,\n\u001b[1;32m    298\u001b[0m     name\u001b[39m=\u001b[39mrun_name,\n\u001b[1;32m    299\u001b[0m )\n\u001b[1;32m    300\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    301\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 302\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs, run_manager\u001b[39m=\u001b[39mrun_manager)\n\u001b[1;32m    303\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    304\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[1;32m    305\u001b[0m     )\n\u001b[1;32m    306\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    307\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/Downloads/important_software/anaconda3/lib/python3.11/site-packages/langchain/chains/retrieval_qa/base.py:136\u001b[0m, in \u001b[0;36mBaseRetrievalQA._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    132\u001b[0m accepts_run_manager \u001b[39m=\u001b[39m (\n\u001b[1;32m    133\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mrun_manager\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m inspect\u001b[39m.\u001b[39msignature(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_docs)\u001b[39m.\u001b[39mparameters\n\u001b[1;32m    134\u001b[0m )\n\u001b[1;32m    135\u001b[0m \u001b[39mif\u001b[39;00m accepts_run_manager:\n\u001b[0;32m--> 136\u001b[0m     docs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_docs(question, run_manager\u001b[39m=\u001b[39m_run_manager)\n\u001b[1;32m    137\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    138\u001b[0m     docs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_docs(question)  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n",
      "File \u001b[0;32m~/Downloads/important_software/anaconda3/lib/python3.11/site-packages/langchain/chains/retrieval_qa/base.py:216\u001b[0m, in \u001b[0;36mRetrievalQA._get_docs\u001b[0;34m(self, question, run_manager)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_docs\u001b[39m(\n\u001b[1;32m    210\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    211\u001b[0m     question: \u001b[39mstr\u001b[39m,\n\u001b[1;32m    212\u001b[0m     \u001b[39m*\u001b[39m,\n\u001b[1;32m    213\u001b[0m     run_manager: CallbackManagerForChainRun,\n\u001b[1;32m    214\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Document]:\n\u001b[1;32m    215\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Get docs.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretriever\u001b[39m.\u001b[39mget_relevant_documents(\n\u001b[1;32m    217\u001b[0m         question, callbacks\u001b[39m=\u001b[39mrun_manager\u001b[39m.\u001b[39mget_child()\n\u001b[1;32m    218\u001b[0m     )\n",
      "File \u001b[0;32m~/Downloads/important_software/anaconda3/lib/python3.11/site-packages/langchain/schema/retriever.py:211\u001b[0m, in \u001b[0;36mBaseRetriever.get_relevant_documents\u001b[0;34m(self, query, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    210\u001b[0m     run_manager\u001b[39m.\u001b[39mon_retriever_error(e)\n\u001b[0;32m--> 211\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    212\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    213\u001b[0m     run_manager\u001b[39m.\u001b[39mon_retriever_end(\n\u001b[1;32m    214\u001b[0m         result,\n\u001b[1;32m    215\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    216\u001b[0m     )\n",
      "File \u001b[0;32m~/Downloads/important_software/anaconda3/lib/python3.11/site-packages/langchain/schema/retriever.py:204\u001b[0m, in \u001b[0;36mBaseRetriever.get_relevant_documents\u001b[0;34m(self, query, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m _kwargs \u001b[39m=\u001b[39m kwargs \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expects_other_args \u001b[39melse\u001b[39;00m {}\n\u001b[1;32m    203\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_new_arg_supported:\n\u001b[0;32m--> 204\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_relevant_documents(\n\u001b[1;32m    205\u001b[0m         query, run_manager\u001b[39m=\u001b[39mrun_manager, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m_kwargs\n\u001b[1;32m    206\u001b[0m     )\n\u001b[1;32m    207\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_relevant_documents(query, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m_kwargs)\n",
      "File \u001b[0;32m~/Downloads/important_software/anaconda3/lib/python3.11/site-packages/langchain/schema/vectorstore.py:585\u001b[0m, in \u001b[0;36mVectorStoreRetriever._get_relevant_documents\u001b[0;34m(self, query, run_manager)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_relevant_documents\u001b[39m(\n\u001b[1;32m    582\u001b[0m     \u001b[39mself\u001b[39m, query: \u001b[39mstr\u001b[39m, \u001b[39m*\u001b[39m, run_manager: CallbackManagerForRetrieverRun\n\u001b[1;32m    583\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Document]:\n\u001b[1;32m    584\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msearch_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msimilarity\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 585\u001b[0m         docs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvectorstore\u001b[39m.\u001b[39msimilarity_search(query, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msearch_kwargs)\n\u001b[1;32m    586\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msearch_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msimilarity_score_threshold\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    587\u001b[0m         docs_and_similarities \u001b[39m=\u001b[39m (\n\u001b[1;32m    588\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvectorstore\u001b[39m.\u001b[39msimilarity_search_with_relevance_scores(\n\u001b[1;32m    589\u001b[0m                 query, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msearch_kwargs\n\u001b[1;32m    590\u001b[0m             )\n\u001b[1;32m    591\u001b[0m         )\n",
      "File \u001b[0;32m~/Downloads/important_software/anaconda3/lib/python3.11/site-packages/langchain/vectorstores/chroma.py:261\u001b[0m, in \u001b[0;36mChroma.similarity_search\u001b[0;34m(self, query, k, filter, **kwargs)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msimilarity_search\u001b[39m(\n\u001b[1;32m    245\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    246\u001b[0m     query: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    250\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Document]:\n\u001b[1;32m    251\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Run similarity search with Chroma.\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \n\u001b[1;32m    253\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[39m        List[Document]: List of documents most similar to the query text.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 261\u001b[0m     docs_and_scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msimilarity_search_with_score(query, k, \u001b[39mfilter\u001b[39m\u001b[39m=\u001b[39m\u001b[39mfilter\u001b[39m)\n\u001b[1;32m    262\u001b[0m     \u001b[39mreturn\u001b[39;00m [doc \u001b[39mfor\u001b[39;00m doc, _ \u001b[39min\u001b[39;00m docs_and_scores]\n",
      "File \u001b[0;32m~/Downloads/important_software/anaconda3/lib/python3.11/site-packages/langchain/vectorstores/chroma.py:345\u001b[0m, in \u001b[0;36mChroma.similarity_search_with_score\u001b[0;34m(self, query, k, filter, where_document, **kwargs)\u001b[0m\n\u001b[1;32m    338\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__query_collection(\n\u001b[1;32m    339\u001b[0m         query_texts\u001b[39m=\u001b[39m[query],\n\u001b[1;32m    340\u001b[0m         n_results\u001b[39m=\u001b[39mk,\n\u001b[1;32m    341\u001b[0m         where\u001b[39m=\u001b[39m\u001b[39mfilter\u001b[39m,\n\u001b[1;32m    342\u001b[0m         where_document\u001b[39m=\u001b[39mwhere_document,\n\u001b[1;32m    343\u001b[0m     )\n\u001b[1;32m    344\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 345\u001b[0m     query_embedding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_embedding_function\u001b[39m.\u001b[39membed_query(query)\n\u001b[1;32m    346\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__query_collection(\n\u001b[1;32m    347\u001b[0m         query_embeddings\u001b[39m=\u001b[39m[query_embedding],\n\u001b[1;32m    348\u001b[0m         n_results\u001b[39m=\u001b[39mk,\n\u001b[1;32m    349\u001b[0m         where\u001b[39m=\u001b[39m\u001b[39mfilter\u001b[39m,\n\u001b[1;32m    350\u001b[0m         where_document\u001b[39m=\u001b[39mwhere_document,\n\u001b[1;32m    351\u001b[0m     )\n\u001b[1;32m    353\u001b[0m \u001b[39mreturn\u001b[39;00m _results_to_docs_and_scores(results)\n",
      "File \u001b[0;32m~/Downloads/important_software/anaconda3/lib/python3.11/site-packages/langchain/embeddings/openai.py:518\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_query\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39membed_query\u001b[39m(\u001b[39mself\u001b[39m, text: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[\u001b[39mfloat\u001b[39m]:\n\u001b[1;32m    510\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call out to OpenAI's embedding endpoint for embedding query text.\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \n\u001b[1;32m    512\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[39m        Embedding for the text.\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_documents([text])[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/Downloads/important_software/anaconda3/lib/python3.11/site-packages/langchain/embeddings/openai.py:490\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_documents\u001b[0;34m(self, texts, chunk_size)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Call out to OpenAI's embedding endpoint for embedding search docs.\u001b[39;00m\n\u001b[1;32m    479\u001b[0m \n\u001b[1;32m    480\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[39m    List of embeddings, one for each text.\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \u001b[39m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[1;32m    489\u001b[0m \u001b[39m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[0;32m--> 490\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_len_safe_embeddings(texts, engine\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdeployment)\n",
      "File \u001b[0;32m~/Downloads/important_software/anaconda3/lib/python3.11/site-packages/langchain/embeddings/openai.py:374\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[0;34m(self, texts, engine, chunk_size)\u001b[0m\n\u001b[1;32m    371\u001b[0m     _iter \u001b[39m=\u001b[39m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(tokens), _chunk_size)\n\u001b[1;32m    373\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m _iter:\n\u001b[0;32m--> 374\u001b[0m     response \u001b[39m=\u001b[39m embed_with_retry(\n\u001b[1;32m    375\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m    376\u001b[0m         \u001b[39minput\u001b[39m\u001b[39m=\u001b[39mtokens[i : i \u001b[39m+\u001b[39m _chunk_size],\n\u001b[1;32m    377\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_invocation_params,\n\u001b[1;32m    378\u001b[0m     )\n\u001b[1;32m    379\u001b[0m     batched_embeddings\u001b[39m.\u001b[39mextend(r[\u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m response[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    381\u001b[0m results: List[List[List[\u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m [[] \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(texts))]\n",
      "File \u001b[0;32m~/Downloads/important_software/anaconda3/lib/python3.11/site-packages/langchain/embeddings/openai.py:107\u001b[0m, in \u001b[0;36membed_with_retry\u001b[0;34m(embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m     response \u001b[39m=\u001b[39m embeddings\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    105\u001b[0m     \u001b[39mreturn\u001b[39;00m _check_response(response, skip_empty\u001b[39m=\u001b[39membeddings\u001b[39m.\u001b[39mskip_empty)\n\u001b[0;32m--> 107\u001b[0m \u001b[39mreturn\u001b[39;00m _embed_with_retry(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Downloads/important_software/anaconda3/lib/python3.11/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(f, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n",
      "File \u001b[0;32m~/Downloads/important_software/anaconda3/lib/python3.11/site-packages/tenacity/__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miter(retry_state\u001b[39m=\u001b[39mretry_state)\n\u001b[1;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Downloads/important_software/anaconda3/lib/python3.11/site-packages/tenacity/__init__.py:314\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    312\u001b[0m is_explicit_retry \u001b[39m=\u001b[39m fut\u001b[39m.\u001b[39mfailed \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(fut\u001b[39m.\u001b[39mexception(), TryAgain)\n\u001b[1;32m    313\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (is_explicit_retry \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretry(retry_state)):\n\u001b[0;32m--> 314\u001b[0m     \u001b[39mreturn\u001b[39;00m fut\u001b[39m.\u001b[39mresult()\n\u001b[1;32m    316\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter(retry_state)\n",
      "File \u001b[0;32m~/Downloads/important_software/anaconda3/lib/python3.11/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[1;32m    451\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/Downloads/important_software/anaconda3/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Downloads/important_software/anaconda3/lib/python3.11/site-packages/tenacity/__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m         result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    383\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n\u001b[1;32m    384\u001b[0m         retry_state\u001b[39m.\u001b[39mset_exception(sys\u001b[39m.\u001b[39mexc_info())  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/Downloads/important_software/anaconda3/lib/python3.11/site-packages/langchain/embeddings/openai.py:104\u001b[0m, in \u001b[0;36membed_with_retry.<locals>._embed_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[1;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_embed_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m--> 104\u001b[0m     response \u001b[39m=\u001b[39m embeddings\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    105\u001b[0m     \u001b[39mreturn\u001b[39;00m _check_response(response, skip_empty\u001b[39m=\u001b[39membeddings\u001b[39m.\u001b[39mskip_empty)\n",
      "File \u001b[0;32m~/Downloads/important_software/anaconda3/lib/python3.11/site-packages/openai/api_resources/embedding.py:33\u001b[0m, in \u001b[0;36mEmbedding.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m         response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     35\u001b[0m         \u001b[39m# If a user specifies base64, we'll just return the encoded string.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m         \u001b[39m# This is only for the default case.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m user_provided_encoding_format:\n",
      "File \u001b[0;32m~/Downloads/important_software/anaconda3/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py:155\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    130\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    131\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    139\u001b[0m ):\n\u001b[1;32m    140\u001b[0m     (\n\u001b[1;32m    141\u001b[0m         deployment_id,\n\u001b[1;32m    142\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    152\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    153\u001b[0m     )\n\u001b[0;32m--> 155\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39mrequest(\n\u001b[1;32m    156\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    157\u001b[0m         url,\n\u001b[1;32m    158\u001b[0m         params\u001b[39m=\u001b[39mparams,\n\u001b[1;32m    159\u001b[0m         headers\u001b[39m=\u001b[39mheaders,\n\u001b[1;32m    160\u001b[0m         stream\u001b[39m=\u001b[39mstream,\n\u001b[1;32m    161\u001b[0m         request_id\u001b[39m=\u001b[39mrequest_id,\n\u001b[1;32m    162\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    165\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    166\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    167\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/Downloads/important_software/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py:299\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    279\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    280\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    287\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    288\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    289\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    290\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    291\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    297\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    298\u001b[0m     )\n\u001b[0;32m--> 299\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response(result, stream)\n\u001b[1;32m    300\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/Downloads/important_software/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py:710\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    702\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    703\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    704\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    707\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    708\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    709\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 710\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    711\u001b[0m             result\u001b[39m.\u001b[39mcontent\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m    712\u001b[0m             result\u001b[39m.\u001b[39mstatus_code,\n\u001b[1;32m    713\u001b[0m             result\u001b[39m.\u001b[39mheaders,\n\u001b[1;32m    714\u001b[0m             stream\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    715\u001b[0m         ),\n\u001b[1;32m    716\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    717\u001b[0m     )\n",
      "File \u001b[0;32m~/Downloads/important_software/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py:775\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    773\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    774\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 775\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    776\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    777\u001b[0m     )\n\u001b[1;32m    778\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mAuthenticationError\u001b[0m: Incorrect API key provided: sk-8y8iE***************************************MZdG. You can find your API key at https://platform.openai.com/account/api-keys."
     ]
    }
   ],
   "source": [
    " #Applying the RetrievalQA chain ('qachain') to generate predictions on modified data\n",
    "prediction=qachain.apply(modified_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'query': 'How many transactions does Visa process per second?',\n",
       "  'answer': 'Approximately 6800 transactions per second.',\n",
       "  'result': \" I don't know.\"},\n",
       " {'query': 'What is one advantage that data mining has over classical statistics?',\n",
       "  'answer': 'Data mining has the advantage of being able to partition the data set so that a model developed for the training data set can be tested for reliability on other data.',\n",
       "  'result': ' Data mining can turn raw medical records into medical knowledge, which can be used to detect trends in medical practice and even alter medical practice. Classical statistics is not as well-suited to this task.'},\n",
       " {'query': 'According to the American Statistical Association\\'s \"Ethical Guidelines for Statistical Practice,\" what is considered unethical statistical behavior?',\n",
       "  'answer': 'Unethical statistical behavior includes running multiple tests until a desired result is obtained, discarding data to provide an average that is higher than the original result, and not accounting for and explaining all data that was considered in a study.',\n",
       "  'result': ' According to the American Statistical Association\\'s \"Ethical Guidelines for Statistical Practice,\" unethical statistical behavior includes misrepresenting data, failing to disclose significant limitations in data, or misusing statistical techniques.'}]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an evaluation chain for question-answering using an LLM (llm)\n",
    "evalutions=QAEvalChain.from_llm(\n",
    "    llm=llm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the initialized evaluations chain ('evaluations') to evaluate the generated predictions ('prediction')\n",
    "evaluate=evalutions.evaluate(modified_data,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'results': ' INCORRECT'}, {'results': ' CORRECT'}, {'results': ' CORRECT'}]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate[:3] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 0:\n",
      "Question: How many transactions does Visa process per second?\n",
      "Real Answer: Approximately 6800 transactions per second.\n",
      "Predicted Answer:  I don't know.\n",
      "Predicted Grade:  INCORRECT\n",
      "\n",
      "Example 1:\n",
      "Question: What is one advantage that data mining has over classical statistics?\n",
      "Real Answer: Data mining has the advantage of being able to partition the data set so that a model developed for the training data set can be tested for reliability on other data.\n",
      "Predicted Answer:  Data mining can turn raw medical records into medical knowledge, which can be used to detect trends in medical practice and even alter medical practice. Classical statistics is not as well-suited to this task.\n",
      "Predicted Grade:  CORRECT\n",
      "\n",
      "Example 2:\n",
      "Question: According to the American Statistical Association's \"Ethical Guidelines for Statistical Practice,\" what is considered unethical statistical behavior?\n",
      "Real Answer: Unethical statistical behavior includes running multiple tests until a desired result is obtained, discarding data to provide an average that is higher than the original result, and not accounting for and explaining all data that was considered in a study.\n",
      "Predicted Answer:  According to the American Statistical Association's \"Ethical Guidelines for Statistical Practice,\" unethical statistical behavior includes misrepresenting data, failing to disclose significant limitations in data, or misusing statistical techniques.\n",
      "Predicted Grade:  CORRECT\n",
      "\n",
      "Example 3:\n",
      "Question: According to the document, what are the four scales of measurement used to obtain data on a particular variable?\n",
      "Real Answer: The four scales of measurement used to obtain data on a particular variable are nominal, ordinal, interval, and ratio.\n",
      "Predicted Answer:  This document does not mention any scales of measurement used to obtain data on a particular variable.\n",
      "Predicted Grade:  INCORRECT\n",
      "\n",
      "Example 4:\n",
      "Question: What is Big Data characterized by?\n",
      "Real Answer: Big Data is characterized by great volume (a large amount of data), high velocity (fast collection and processing), or wide variety (could include nontraditional data such as video, audio, and text).\n",
      "Predicted Answer:  Big Data is characterized by its large volume, variety, velocity, and veracity.\n",
      "Predicted Grade:  CORRECT\n",
      "\n",
      "Example 5:\n",
      "Question: How many variables are in the data set in Table 1.6?\n",
      "Real Answer: There are 5 variables in the data set in Table 1.6.\n",
      "Predicted Answer:  This question does not have anything to do with the context given.\n",
      "Predicted Grade:  INCORRECT\n",
      "\n",
      "Example 6:\n",
      "Question: What percentage of the cordless telephones have a voice quality of excellent?\n",
      "Real Answer: 7/8 (87.5%) of the cordless telephones have a voice quality of excellent.\n",
      "Predicted Answer:  I don't know.\n",
      "Predicted Grade:  INCORRECT\n",
      "\n",
      "Example 7:\n",
      "Question: What percentage of respondents in the Bureau of Transportation Statistics Omnibus Household Survey said that they strongly disagree with allowing drivers of motor vehicles to talk on a hand-held cell phone while driving?\n",
      "Real Answer: 741 respondents (74.1%) said that they strongly disagree with allowing drivers of motor vehicles to talk on a hand-held cell phone while driving.\n",
      "Predicted Answer:  I don't know.\n",
      "Predicted Grade:  INCORRECT\n",
      "\n",
      "Example 8:\n",
      "Question: According to the document, what is the trend in Google revenue over time?\n",
      "Real Answer: The trend in Google revenue over time is increasing.\n",
      "Predicted Answer:  I don't know.\n",
      "Predicted Grade:  INCORRECT\n",
      "\n",
      "Example 9:\n",
      "Question: What percentage of the total number of accident reports for the year were filed in January and December?\n",
      "Real Answer: 61 accident reports were filed in January, and 76 accident reports were filed in December, representing a total of 137 accident reports. This represents 2.91% of the total number of accident reports filed in 2009.\n",
      "Predicted Answer:  I don't know.\n",
      "Predicted Grade:  INCORRECT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, eg in enumerate(examples):\n",
    "    print(f\"Example {i}:\")\n",
    "    print(\"Question: \" + prediction[i]['query'])\n",
    "    print(\"Real Answer: \" + prediction[i]['answer'])\n",
    "    print(\"Predicted Answer: \" + prediction[i]['result'])\n",
    "    print(\"Predicted Grade: \" + evaluate[i][\"results\"])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doc': Document(page_content='MachineLearning-Lecture01  \\nInstructor (Andrew Ng):  Okay. Good morning. Welcome to CS229, the machine \\nlearning class. So what I wanna do today is ju st spend a little time going over the logistics \\nof the class, and then we\\'ll start to  talk a bit about machine learning.  \\nBy way of introduction, my name\\'s  Andrew Ng and I\\'ll be instru ctor for this class. And so \\nI personally work in machine learning, and I\\' ve worked on it for about 15 years now, and \\nI actually think that machine learning is th e most exciting field of all the computer \\nsciences. So I\\'m actually always excited about  teaching this class. Sometimes I actually \\nthink that machine learning is not only the most exciting thin g in computer science, but \\nthe most exciting thing in all of human e ndeavor, so maybe a little bias there.  \\nI also want to introduce the TAs, who are all graduate students doing research in or \\nrelated to the machine learni ng and all aspects of machin e learning. Paul Baumstarck \\nworks in machine learning and computer vision.  Catie Chang is actually a neuroscientist \\nwho applies machine learning algorithms to try to understand the human brain. Tom Do \\nis another PhD student, works in computa tional biology and in sort of the basic \\nfundamentals of human learning. Zico Kolter is  the head TA — he\\'s head TA two years \\nin a row now — works in machine learning a nd applies them to a bunch of robots. And \\nDaniel Ramage is — I guess he\\'s not here  — Daniel applies l earning algorithms to \\nproblems in natural language processing.  \\nSo you\\'ll get to know the TAs and me much be tter throughout this quarter, but just from \\nthe sorts of things the TA\\'s do, I hope you can  already tell that machine learning is a \\nhighly interdisciplinary topic in which just the TAs find l earning algorithms to problems \\nin computer vision and biology and robots a nd language. And machine learning is one of \\nthose things that has and is having a large impact on many applications.  \\nSo just in my own daily work, I actually frequently end up talking to people like \\nhelicopter pilots to biologists to people in  computer systems or databases to economists \\nand sort of also an unending stream of  people from industry coming to Stanford \\ninterested in applying machine learni ng methods to their own problems.  \\nSo yeah, this is fun. A couple of weeks ago, a student actually forwar ded to me an article \\nin \"Computer World\" about the 12 IT skills th at employers can\\'t say no to. So it\\'s about \\nsort of the 12 most desirabl e skills in all of IT and all of information technology, and \\ntopping the list was actually machine lear ning. So I think this is a good time to be \\nlearning this stuff and learning algorithms and having a large impact on many segments \\nof science and industry.  \\nI\\'m actually curious about something. Learni ng algorithms is one of the things that \\ntouches many areas of science and industrie s, and I\\'m just kind of curious. How many \\npeople here are computer science majors, are in the computer science department? Okay. \\nAbout half of you. How many people are from  EE? Oh, okay, maybe about a fifth. How ', metadata={'source': './MachineLearning-Lecture01.pdf', 'page': 0})}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'LLMChain' has no attribute 'output_parser'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LLMChain\n\u001b[0;32m----> 2\u001b[0m llm_chain \u001b[38;5;241m=\u001b[39m LLMChain\u001b[38;5;241m.\u001b[39moutput_parser(llm\u001b[38;5;241m=\u001b[39mllm)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(llm_chain\u001b[38;5;241m.\u001b[39mapply(load))\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'LLMChain' has no attribute 'output_parser'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello there! How can I assist you today?')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain.evaluation.qa.eval_chain.QAEvalChain"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "78a73e9cea53431a004a8cb57099f417374d636685740d6545615ecc2fea032b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
