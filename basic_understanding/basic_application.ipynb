{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.output_parsers import ResponseSchema,StructuredOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "openai.api_key=os.getenv(\"basit_key\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat=ChatOpenAI(\n",
    "    temperature=0.0, model=\"gpt-3.5-turbo\",api_key=os.getenv(\"basit_key\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, \n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=f\"\"\"Translate the text \\\n",
    "that is delimited by triple backticks \n",
    "into a style that is \"American English \\\n",
    "in a calm and respectful tone\".\n",
    "text: ```Nous espérons que vous allez bien. Nous tenons à vous remercier pour votre confiance en notre produit, et nous sommes désolés d'apprendre que vous rencontrez des problèmes avec votre machine à laver.\\\n",
    "    Nous comprenons à quel point il est essentiel d'avoir un appareil fonctionnel à la maison, en particulier votre machine à laver. Nous voulons résoudre ce problème le plus rapidement possible```\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"We hope you\\'re doing well. We want to thank you for your trust in our product, and we\\'re sorry to hear that you\\'re experiencing issues with your washing machine. We understand how important it is to have a functional appliance at home, especially your washing machine. We want to resolve this issue as quickly as possible.\"'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_completion(prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_string = \"\"\"Translate the text \\\n",
    "that is delimited by triple backticks \\\n",
    "in style tto ahat is {style}. \\\n",
    "text: ```{text}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['style', 'text']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "prompt_template=ChatPromptTemplate.from_template(template_string)\n",
    "prompt_template.messages[0].prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_text=\"chal bhai jaa yehan say.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_style=\"\"\"American English \\\n",
    "in a harsh tone\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_message=prompt_template.format_messages(\n",
    "    style=text_style,\n",
    "    text=customer_text\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_responce=chat(customer_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Get lost, dude.'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_responce.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_reply = \"\"\"Hey there customer, \\\n",
    "the warranty does not cover \\\n",
    "cleaning expenses for your kitchen \\\n",
    "because it's your fault that \\\n",
    "you misused your blender \\\n",
    "by forgetting to put the lid on before \\\n",
    "starting the blender. \\\n",
    "Tough luck! See ya!\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_style=\"a ploite tone/ thats speaks ub pirate english\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_reply=prompt_template.format_messages(\n",
    "    text=service_reply,\n",
    "    style=service_style\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_responce=chat(service_reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Arr, me heartie customer, the warranty be not coverin' the cleanin' expenses fer yer galley 'cause 'tis yer fault ye misused yer blender by forgettin' to put the lid on afore startin' the blender. Tough luck, me matey! Fare thee well!\""
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "service_responce.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "own_prompt=\"\"\"I recently purchased this cookingset with high hopes, but unfortunately, it failed to meet my expectations. The device's performance was inconsistent, with fluctuating heat settings that made styling my hair a bit of a challenge. Moreover, the noise level was surprisingly loud, disrupting my morning routine.\\\n",
    "The build quality left much to be desired; the handle felt fragile, and there was an unpleasant odor emitting from the dryer during use. Overall, I found this product lacking in reliability and quality, especially considering its price.\\\n",
    "In conclusion, I would not recommend this hair dryer based on my experience.\\\n",
    "Emily Smith\n",
    "\n",
    "I recently purchased this cookingset with high hopes, but unfortunately, it failed to meet my expectations. The device's performance was inconsistent, with fluctuating heat settings that made styling my hair a bit of a challenge. Moreover, the noise level was surprisingly loud, disrupting my morning routine.\\\n",
    "The build quality left much to be desired; the handle felt fragile, and there was an unpleasant odor emitting from the dryer during use. Overall, I found this product lacking in reliability and quality, especially considering its price.\\\n",
    "In conclusion, I would not recommend this hair dryer based on my experience.\\\n",
    "Emily Smith\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "template=\"A reviews is given by the customer is tripple backslash and \\\n",
    "    you have to extract the main cause of problem in 2-3 words if there is any, along with name and what they purchased in the following Json format\\\n",
    "    id,customername, product purchased, problem with that product\\\n",
    "    ```{text}```\\\n",
    "    \" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "own_template=prompt_template.from_template(template=template)\n",
    "own_template.messages[0].prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_review=own_template.format_messages(\n",
    "    text=own_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "own_responce=chat(customer_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": 1,\n",
      "  \"customername\": \"Emily Smith\",\n",
      "  \"product purchased\": \"cookingset\",\n",
      "  \"problem with that product\": \"inconsistent performance\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(own_responce.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_schemas =[\n",
    "    ResponseSchema(name=\"id\",description=\"A unique interger\"),\n",
    "ResponseSchema(name=\"customername\",description=\"name of person who purchased the product\"),\n",
    "ResponseSchema(name=\"product purchased\",description=\"name of product\"),\n",
    "ResponseSchema(name=\"problem with that product\",description=\"what really a problem with product\")\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ResponseSchema(name='id', description='A unique interger', type='string'),\n",
       " ResponseSchema(name='customername', description='name of person who purchased the product', type='string'),\n",
       " ResponseSchema(name='product purchased', description='name of product', type='string'),\n",
       " ResponseSchema(name='problem with that product', description='what really a problem with product', type='string')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "```json\n",
      "{\n",
      "\t\"id\": string  // A unique interger\n",
      "\t\"customername\": string  // name of person who purchased the product\n",
      "\t\"product purchased\": string  // name of product\n",
      "\t\"problem with that product\": string  // what really a problem with product\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "output_parser=StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "format_instruction=output_parser.get_format_instructions(\"\"\"he output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\\n",
    "```json\\\n",
    "[{\\\n",
    "\t\"id\": string  // A unique interger\\\n",
    "\t\"customername\": string  // name of person who purchased the product \\\n",
    "\t\"product purchased\": string  // name of product \\\n",
    "\t\"problem with that product\": string  // what really a problem with product\\\n",
    "},\\\n",
    "    \"id\": string  // A unique interger\\\n",
    "\t\"customername\":......\"]\\\n",
    "```\"\"\")\n",
    "\n",
    "print(format_instruction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_with_json=\"reviews is given by the customer is tripple backslash and to separate each review start with another line\\\n",
    "    you have to extract the main cause of problem in 2-3 words if there is any, along with name and what they purchased \\\n",
    "       \\\n",
    "    Format the output as JSON with the following keys :\\\n",
    "    id,customername, product purchased, problem with that product\\\n",
    "    ```{text}\\\n",
    "    {format_instruction}\\\n",
    "    \\\n",
    "    \" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt_json=ChatPromptTemplate.from_template(template=template_with_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['format_instruction', 'text']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt_json.messages[0].prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_prompt=chat_prompt_json.format_messages(text=own_prompt,format_instruction=format_instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reviews is given by the customer is tripple backslash and to separate each review start with another line    you have to extract the main cause of problem in 2-3 words if there is any, along with name and what they purchased            Format the output as JSON with the following keys :    id,customername, product purchased, problem with that product    ```I recently purchased this cookingset with high hopes, but unfortunately, it failed to meet my expectations. The device's performance was inconsistent, with fluctuating heat settings that made styling my hair a bit of a challenge. Moreover, the noise level was surprisingly loud, disrupting my morning routine.The build quality left much to be desired; the handle felt fragile, and there was an unpleasant odor emitting from the dryer during use. Overall, I found this product lacking in reliability and quality, especially considering its price.In conclusion, I would not recommend this hair dryer based on my experience.Emily Smith\n",
      "    The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"id\": string  // A unique interger\n",
      "\t\"customername\": string  // name of person who purchased the product\n",
      "\t\"product purchased\": string  // name of product\n",
      "\t\"problem with that product\": string  // what really a problem with product\n",
      "}\n",
      "```        \n"
     ]
    }
   ],
   "source": [
    "print(json_prompt[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_prompt2=chat(json_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "\t\"id\": \"1\",\n",
      "\t\"customername\": \"Emily Smith\",\n",
      "\t\"product purchased\": \"cookingset\",\n",
      "\t\"problem with that product\": \"inconsistent performance, fluctuating heat settings, loud noise, fragile handle, unpleasant odor\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(json_prompt2.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "\t\"id\": \"1\",\n",
      "\t\"customername\": \"Emily Smith\",\n",
      "\t\"product purchased\": \"cookingset\",\n",
      "\t\"problem with that product\": \"inconsistent performance, fluctuating heat settings, loud noise, fragile handle, unpleasant odor\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(json_prompt2.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=output_parser.parse(json_prompt2.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '1',\n",
       " 'customername': 'Emily Smith',\n",
       " 'product purchased': 'cookingset',\n",
       " 'problem with that product': 'inconsistent performance, fluctuating heat settings, loud noise, fragile handle, unpleasant odor'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "78a73e9cea53431a004a8cb57099f417374d636685740d6545615ecc2fea032b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
