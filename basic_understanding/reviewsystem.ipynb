{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List,Tuple\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.pydantic_v1 import BaseModel, Field, validator\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"text-davinci-003\"\n",
    "temperature = 0.0\n",
    "model = OpenAI(model_name=model_name, temperature=temperature,api_key=os.getenv(\"basit_key\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"setup\": {\"title\": \"Setup\", \"description\": \"question to set up a joke\", \"type\": \"string\"}, \"punchline\": {\"title\": \"Punchline\", \"description\": \"answer to resolve the joke\", \"type\": \"string\"}}, \"required\": [\"setup\", \"punchline\"]}\\n```'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joke_query = \"Tell me a joke.\"\n",
    "parser = PydanticOutputParser(pydantic_object=Joke)\n",
    "parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=PromptTemplate.from_template(template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "_input=prompt.format_prompt(\n",
    "    format_instructions=parser.get_format_instructions(),\n",
    "    query=joke_query\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup='Why did the chicken cross the road?', punchline='To get to the other side!')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "output = model(_input.to_string())\n",
    "\n",
    "parser.parse(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Product(BaseModel):\n",
    "    # id:int = Field(description=\"unique id \")\n",
    "    # productname: str = Field(description=\"Name of a product\")\n",
    "    # customer_name :str = Field(description=\"Name of customer\")\n",
    "    problems: str = Field(description=\"List the customer name and problem with the product\")\n",
    "\n",
    "\n",
    "actor_query = \"\"\"\"I recently purchased this cookingset with high hopes, but unfortunately, it failed to meet my expectations. The device's performance was inconsistent, with fluctuating heat settings that made styling my hair a bit of a challenge. Moreover, the noise level was surprisingly loud, disrupting my morning routine.\\\n",
    "The build quality left much to be desired; the handle felt fragile, I would not recommend this hair dryer based on my experience.\\\n",
    "Emily Smith\n",
    "\n",
    "I recently purchased this hairdyer with high hopes, but unfortunately, it failed to meet my expectations. The device's performance \n",
    "The build quality left much to be desired; the handle felt fragile, I would not recommend this hair dryer based on my experience.\\\n",
    "Basit\n",
    "\"\"\"\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Product)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"list of reviews is given by the customer is tripple backslash and to separate each review start with another line\\\n",
    "    you have to extract the main cause of problem in 1 words if there is any, along with name and what they purchased : in following format\\\n",
    "       id ,problems \\\n",
    "    ```{query}```\\\n",
    "    {format_instructions}\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "_input = prompt.format_prompt(query=actor_query)\n",
    "\n",
    "output = model(_input.to_string())\n",
    "\n",
    "# print(parser.parse(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Output:\n",
      "{\"problems\": [\"Emily Smith - Performance, Build Quality\", \"Basit - Performance, Build Quality\"]}\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutputParserException",
     "evalue": "Failed to parse Product from completion \n\nOutput:\n{\"problems\": [\"Emily Smith - Performance, Build Quality\", \"Basit - Performance, Build Quality\"]}. Got: 1 validation error for Product\nproblems\n  str type expected (type=type_error.str)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/Downloads/important_software/anaconda3/lib/python3.11/site-packages/langchain/output_parsers/pydantic.py:28\u001b[0m, in \u001b[0;36mPydanticOutputParser.parse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     27\u001b[0m     json_object \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mloads(json_str, strict\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m---> 28\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpydantic_object\u001b[39m.\u001b[39mparse_obj(json_object)\n\u001b[1;32m     30\u001b[0m \u001b[39mexcept\u001b[39;00m (json\u001b[39m.\u001b[39mJSONDecodeError, ValidationError) \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Downloads/important_software/anaconda3/lib/python3.11/site-packages/pydantic/v1/main.py:526\u001b[0m, in \u001b[0;36mBaseModel.parse_obj\u001b[0;34m(cls, obj)\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[39mraise\u001b[39;00m ValidationError([ErrorWrapper(exc, loc\u001b[39m=\u001b[39mROOT_KEY)], \u001b[39mcls\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m--> 526\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mobj)\n",
      "File \u001b[0;32m~/Downloads/important_software/anaconda3/lib/python3.11/site-packages/pydantic/v1/main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[39mif\u001b[39;00m validation_error:\n\u001b[0;32m--> 341\u001b[0m     \u001b[39mraise\u001b[39;00m validation_error\n\u001b[1;32m    342\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for Product\nproblems\n  str type expected (type=type_error.str)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[124], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m parser\u001b[38;5;241m.\u001b[39mparse(output)\n",
      "File \u001b[0;32m~/Downloads/important_software/anaconda3/lib/python3.11/site-packages/langchain/output_parsers/pydantic.py:33\u001b[0m, in \u001b[0;36mPydanticOutputParser.parse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     31\u001b[0m name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpydantic_object\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[1;32m     32\u001b[0m msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to parse \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m from completion \u001b[39m\u001b[39m{\u001b[39;00mtext\u001b[39m}\u001b[39;00m\u001b[39m. Got: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 33\u001b[0m \u001b[39mraise\u001b[39;00m OutputParserException(msg, llm_output\u001b[39m=\u001b[39mtext)\n",
      "\u001b[0;31mOutputParserException\u001b[0m: Failed to parse Product from completion \n\nOutput:\n{\"problems\": [\"Emily Smith - Performance, Build Quality\", \"Basit - Performance, Build Quality\"]}. Got: 1 validation error for Product\nproblems\n  str type expected (type=type_error.str)"
     ]
    }
   ],
   "source": [
    "parser.parse(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Product(productname='Cookingset/Hairdryer', Details=['Emily Smith: Inconsistent performance, Loud noise, Poor build quality', 'Basit: Inconsistent performance, Loud noise, Poor build quality'])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.parse(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class ProductEntry(BaseModel):\n",
    "    id:int\n",
    "    customer_name: str = Field(description=\"Name of the customer\")\n",
    "    problem: str = Field(description=\"Problem with the product\")\n",
    "class Review(BaseModel):\n",
    "    Review: list[ProductEntry]\n",
    "\n",
    "\n",
    "\n",
    "review = \"\"\"I recently purchased this cookingset with high hopes, but unfortunately, it failed to meet my expectations. The device's performance was inconsistent, with fluctuating heat settings that made styling my hair a bit of a challenge. Moreover, the noise level was surprisingly loud, disrupting my morning routine.\\\n",
    "The build quality left much to be desired; the handle felt fragile, I would not recommend this hair dryer based on my experience.\\\n",
    "Emily Smith \\\n",
    "\n",
    "I recently purchased this cookingset with fryingpan, but unfortunately, it failed to meet my expectations. The device's performance was inconsistent, with fluctuating heat settings that made styling my hair a bit of a challenge. Moreover, the noise level was surprisingly loud, disrupting my morning routine.\\\n",
    "The build quality left much to be desired; the handle felt fragile, I would not recommend this hair dryer based on my experience.\\\n",
    "Abdul Basit\n",
    "\n",
    "I recently purchased this generator with highhopes, but unfortunately, it failed to meet my expectations. The device's performance was inconsistent, with fluctuating heat settings that made styling my hair a bit of a challenge. Moreover, the noise level was surprisingly loud, disrupting my morning routine.\\\n",
    "The build quality left much to be desired; the handle felt fragile, I would not recommend this hair dryer based on my experience.\\\n",
    "Muhammad Saqib\\\n",
    "\"\"\"\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Review)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"List of reviews given by customers by tripple backslash. Each review starts on a new line. Extract the main cause of the problem in 2-3 words, along with the name and the purchased product.\\n{format_instructions}\\n```{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "_input = prompt.format_prompt(query=review)\n",
    "\n",
    "output = model(_input.to_string())  # Replace 'model' with your actual OpenAI model instance\n",
    "\n",
    "# parsed_output = parser.parse(output)\n",
    "print(type(output))\n",
    "# print(parsed_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"ProductName\": [\"cookingset\", \"cookingset with fryingpan\", \"generator\"], \"Review\": [{\"id\": 1, \"customer_name\": \"Emily Smith\", \"problem\": \"inconsistent performance\"}, {\"id\": 2, \"customer_name\": \"Abdul Basit\", \"problem\": \"inconsistent performance\"}, {\"id\": 3, \"customer_name\": \"Muhammad Saqib\", \"problem\": \"inconsistent performance\"}]}\n"
     ]
    }
   ],
   "source": [
    "parsed_output = parser.parse(output)\n",
    "print(parsed_output.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review(Review=[ProductEntry(id=1, customer_name='Emily Smith', product_name='Cookingset', problem='Inconsistent heat'), ProductEntry(id=2, customer_name='Abdul Basit', product_name='Fryingpan', problem='Inconsistent heat')])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup='Why did the chicken cross the road?', punchline='To get to the other side!')"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Joke(setup='Why did the chicken cross the road?', punchline='To get to the other side!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Productlisted(BaseModel):\n",
    "    productname: str = Field(description=\"name of an actor\")\n",
    "    problem: List[str] = Field(description=\"list of names of films they starred in\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "actor_query = \"I recently purchased this cookingset with high hopes, but unfortunately, it failed to meet my expectations. The device's performance was inconsistent, with fluctuating heat settings that made styling my hair a bit of a challenge. Moreover, the noise level was surprisingly loud, disrupting my morning routine.\\\n",
    "The build quality left much to be desired; the handle felt fragile, I would not recommend this hair dryer based on my experience.\\\n",
    "Emily Smit\"\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Productlisted)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"List of reviews given by customers by tripple backslash. Each review starts on a new line. Extract the main cause of the problem in 2-3 words, along with the name and the purchased product.\\n{format_instructions}\\n```{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "_input = prompt.format_prompt(query=actor_query)\n",
    "\n",
    "output = model(_input.to_string())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Productlisted(productname='Cookingset', problem=['inconsistent performance', 'fluctuating heat', 'loud noise', 'fragile handle'])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.parse(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "78a73e9cea53431a004a8cb57099f417374d636685740d6545615ecc2fea032b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
